<!DOCTYPE html>
<html>
<head>
  <title>My first Vue app</title>
  <script src="https://unpkg.com/vue"></script>
</head>
<body>
  <div id="app">
    <label>--------------------------------------MID2--------------------------------------------</label>
    <ol>
      <li v-for="(value, key) in mid2">
        <button v-on:click="mid2TrueOrFalse(value.result, key, 'T')">T</button>
        <button v-on:click="mid2TrueOrFalse(value.result, key, 'F')">F</button>
        <p style="font-size: 22px;">{{value.description}}</p>
        <p v-bind:style="{ color: value.activeColor}">{{value.answer}}</p>
      </li>
    </ol>
    <label>--------------------------------------MID2 Multi Choice--------------------------------------------</label>
    <ol>
      <li v-for="(value, key) in mid2MultiChoice">
        <p style="font-size: 22px;">{{value.description}}</p>
        <ol type="A">
          <li v-for="(rc, content) in value.choices" style="margin-bottom: 5px;">
            <button v-on:click="mid2Choice(rc, key, content)" v-bind:style="{ color: value.choices[content].color}" style="font-size: 22px;">{{content}}</button>
            <p>{{value.choices[content][1]}}</p>
          </li>
        </ol>
      </li>
    </ol>
    <!--
    <label>--------------------------------------MID1--------------------------------------------</label>
    <ol>
      <li v-for="(value, key) in mid1">
        <button v-on:click="mid1TrueOrFalse(value.result, key, 'T')">T</button>
        <button v-on:click="mid1TrueOrFalse(value.result, key, 'F')">F</button>
        <p>{{value.description}}</p>
        <p v-bind:style="{ color: value.activeColor}">{{value.answer}}</p>
      </li>
    </ol>
    <label>--------------------------------------QUIZ--------------------------------------------</label>
    <ol>
      <li v-for="(value, key) in quiz">
        <button v-on:click="quizTrueOrFalse(value.result, key, 'T')">T</button>
        <button v-on:click="quizTrueOrFalse(value.result, key, 'F')">F</button>
        <p>{{value.description}}</p>
        <p v-bind:style="{ color: value.activeColor}">{{value.answer}}</p>
      </li>
    </ol>
    -->
  </div>
  <script>
    var app = new Vue({
      el: '#app',
      data: {
        mid2MultiChoice: {
          q1:{
            description : 'Which of the following statements are generally true?',
            choices: {
              'Memory hierarchies take advantage of temporal locality': {
                result: 'F',
                color: 'black'
              },
              'On a read, the value returned depends on which blocks are in the cache.': {
                result: 'F',
                color: 'black'
              },
              'Most of the cost of the memory hierarchy is at the highest level.': {
                result: 'F',
                color: 'black'
              },
              'Most of the cost of the memory hierarchy is at the lowest level.': {
                result: 'T',
                color: 'black'
              },
            },
          },
          q2:{
            description : '64KB cache with 16-byte block size and a 32-bit address. What type of a cache would require 16 bits for Tag information?',
            choices: {
              'Fully associative cache': {
                result: 'F',
                color: 'black'
              },
              'Directed-mapped cache': {
                result: 'T',
                color: 'black'
              },
              ' 2-way associative cache': {
                result: 'F',
                color: 'black'
              },
              '4-way associative cache': {
                result: 'F',
                color: 'black'
              },
            },
          },
          q3:{
            description : '64KB cache with four-word block size (a word is 4 bytes) and a 32-bit address. If a block has 28 tag bits, what is the type of this cache?',
            choices: {
              '2-way set associative': {
                result: 'F',
                color: 'black'
              },
              'Direct mapped': {
                result: 'F',
                color: 'black'
              },
              'Fully associative': {
                result: 'T',
                color: 'black'
              },
              '4-way set associative': {
                result: 'F',
                color: 'black'
              },
            },
          },
          q4:{
            description : 'Which one of the following processors has the highest possible MIPS rate, assuming full compiler optimization and no cache misses?',
            choices: {
              'A 4-issue processor driven by a 300 MHz clock.': {
                result: 'F',
                color: 'black'
              },
              'A single-issue processor driven by a 1.2 GHz clock': {
                result: 'F',
                color: 'black'
              },
              'A 2-issue processor with a 600 MHz clock.': {
                result: 'F',
                color: 'black'
              },
              'A 8-issue VLIW processor driven by a 200 MHz clock.': {
                result: 'T',
                color: 'black'
              },
            },
          },
          q5:{
            description : 'GPU hardware handles: ',
            choices: {
              'thread management': {
                result: 'T',
                color: 'black'
              },
              'OS': {
                result: 'F',
                color: 'black'
              },
              'applications': {
                result: 'F',
                color: 'black'
              },
              'none': {
                result: 'F',
                color: 'black'
              },
            },
          },
          q6:{
            description : 'Which of the following statement is NOT true on the Centralized Shared-Memory Architectures?',
            choices: {
              'The use of large multilevel caches can substantially reduce memory bandwidth demands of a processor.': {
                result: 'F',
                color: 'black'
              },
              'Bandwidth of the centralized memory system grows as the number of processors in machines increases.': {
                result: 'T',
                color: 'black'
              },
              'It is possible for several (micro)processors to share the same memory through a shared bus.': {
                result: 'F',
                color: 'black'
              },
            },
          },
          q7:{
            description : 'Symmetric multiprocessors architectures, are sometimes known as:',
            choices: {
              'Variable memory access': {
                result: 'F',
                color: 'black'
              },
              'Static memory access': {
                result: 'F',
                color: 'black'
              },
              'Uniform memory access': {
                result: 'T',
                color: 'black'
              },
            },
          },
          q8:{
            description : 'Which of the following systems is the least scalable with respect to its number of processors?',
            choices: {
              'Cache-coherent NUMA systems': {
                result: 'F',
                color: 'black'
              },
              'None': {
                result: 'F',
                color: 'black'
              },
              'Symmetric multiprocessors': {
                result: 'T',
                color: 'black'
              },
              'Noncache-coherent NUMA systems': {
                result: 'F',
                color: 'black'
              },
            },
          },
        },
        mid2: {
          q1:{
            description : 'High associativity in a cache reduces compulsory misses',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q2:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower hit time than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q3:{
            description : 'SRAMs are optimized for storage density.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q4:{
            description : 'TLBs are placed on a special cache memory.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q5:{
            description : 'SIMD architectures exploits instruction-level parallelism.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q6:{
            description : 'Processors with lower CPIs will always be faster.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q7:{
            description : 'Parallelism at data level means parallel execution of multiple instructions of the same type.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q8:{
            description : 'Designating a preferred thread sacrifices throughput.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q9:{
            description : 'Amdahl’s Law doesn’t apply to parallel computers',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q10:{
            description : 'Data-level parallelism achieved by performing the same operation on independent data',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q11:{
            description : 'A Shared Address Space programming model can be used on large scale multiprocessors.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q10:{
            description : 'Clusters have separate memories and thus need many copies of the operating system.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
        },
        mid1: {
          q1:{
            description : 'Increasing the size of a cache results in lower miss rates and higher performance.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q2:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower hit time than a direct-mapped implementation',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q3:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower miss penalty than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q4:{
            description : 'Memory buses are usually picked based on the speed whereas the I/O buses are primarily adopted based on the compatibility (industry standards) and cost',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q5:{
            description : 'Asynchronous buses cannot be long due to clock skew restrictions.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q6:{
            description : '\'Polling\' is always a better mechanism than \'interrupts\' for handling I/O operations on a network interface card',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q7:{
            description : 'In a write-through cache, a read miss can cause a write to the lower memory level.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q8:{
            description : 'SRAMs must be refreshed periodically to prevent loss of information.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q9:{
            description : 'Magnetic disks are volatile storage devices.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q10:{
            description : 'An asynchronous bus is not clocked.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q11:{
            description : 'Victim caches decrease miss penalty while they increase miss rate.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q12:{
            description : 'RAID 5 uses more check disks than RAID 3 for the same number of data disks.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q13:{
            description : 'Direct-mapped cache of size N has same miss rate as 2-way set associative of size N/2.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q14:{
            description : 'The main difference between DRAM (the technology used to implement main memory) and SRAM (the technology used to implement caches) is that DRAM is optimized for access speed while SRAM is optimized for density',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q15:{
            description : 'If the I/O devices are connected to the CPU through main memory busses, the performance of the processor may decrease since I/O commands could interfere with CPU memory accesses.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q16:{
            description : 'Increasing the size of a cache results in lower miss rates and higher performance. ',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q17:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower hit time than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q18:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower miss penalty than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q19:{
            description : 'Memory buses are usually picked based on the speed whereas the I/O buses are primarily adopted based on the compatibility (industry standards) and cost.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q20:{
            description : 'Asynchronous buses cannot be long due to clock skew restrictions.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q21:{
            description : '\'Polling\' is always a better mechanism than \'interrupts\' for handling I/O operations on a network interface card.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q22:{
            description : 'In a write-through cache, a read miss can cause a write to the lower memory level.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q23:{
            description : 'RAID 5 can recover from a two-disk failure ',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q24:{
            description : 'ATM has a variable message size and Ethernet has a fixed message size',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q25:{
            description : 'Loop-carried dependencies can be completely eliminated by a hardware mechanism at run-time.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q26:{
            description : 'The multi-cycle data path is always faster than the single-cycle data path.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q27:{
            description : 'Loops with intra-iteration dependencies can be executed in parallel.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q28:{
            description : 'Software Pipelining can be used on superscalar processors.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q29:{
            description : 'It is possible to eliminate all the stalls due to data dependencies with a special hardware mechanism.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q30:{
            description : 'Conflict misses do not occur in fully set-associative cache memories.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q31:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a higher hit time than a direct-mapped implementation.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q32:{
            description : 'Page tables in virtual memory systems are placed on a special cache memory',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q33:{
            description : 'Y is p\% faster than X\" can be defined as: time of Y / time of X = 1 + p/100',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q34:{
            description : 'Virtually addressable caches would have less hit time than physically addressable cache memories',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q35:{
            description : 'TLB misses in a virtual memory system can occur and can be handled by software',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q36:{
            description : 'In a write-back cache, a read miss always causes a write to the lower memory level.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q37:{
            description : 'Branch history tables typically eliminate more stall cycles than branch target buffers.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q38:{
            description : 'Both DRAM and SRAM must be refreshed periodically using a dummy read/write operation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q39:{
            description : 'Memory interleaving is a technique for reducing memory access time through increased bandwidth utilization of the data bus',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q40:{
            description : 'Control dependencies can be completely eliminated with a special hardware mechanism',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q41:{
            description : 'Compulsory misses do not occur in fully-set associative cache memories',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q42:{
            description : 'In a Write-Throug cache, a read miss always cause a write to the lower memory level',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q43:{
            description : 'DRAMs must be refreshed periodically using a dummy read/write operation.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q44:{
            description : 'Page Tables in Virtual Memory system are placed on a special cache memory.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q45:{
            description : 'RISC architectures are suitable for portable electronic devices.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
        },
        quiz: {
          q1:{
            description : 'performance is indirectly proportional to the system clock frequency.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q2:{
            description : 'CISC architectures are more suitable for portable electronic devices than RISC.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q3:{
            description : 'Processors with faster clock rates will always be faster.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q4:{
            description : 'Name dependencies can be completely eliminated by a hardware mechanism at run-time',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q5:{
            description : 'Loops with no inter-iteration (loop-carried) dependencies can be executed in parallel.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q6:{
            description : 'Data forwarding can resolve all data hazards',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q7:{
            description : 'Pipelining increases overall instruction throughput but also increases individual instruction latency',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q8:{
            description : 'RAID 5 can recover from a two-disk failure.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q9:{
            description : 'Data dependencies can always be avoided by a bypass logic.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q10:{
            description : 'ADD instruction requires data memory access.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q11:{
            description : 'If there are 5 stages in a pipeline, then 5 is the maximum possible speedup.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q12:{
            description : 'RAW hazard is a control hazard.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q13:{
            description : 'Magnetic disks are volatile storage devices.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q14:{
            description : 'As compared to a single-cycled datapath, a pipelined datapath has lower latency and higher throughput.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q15:{
            description : 'High associativity in a cache reduces compulsory misses.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q16:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower hit time than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q17:{
            description : 'In a Write-Through cache, a read miss always causes a write to the lower memory level.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q18:{
            description : 'RAID systems can have catastrophic failures.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
          q19:{
            description : 'High associativity in a cache reduces compulsory misses.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q20:{
            description : 'For a given capacity and block size, a set-associative cache implementation will typically have a lower hit time than a direct-mapped implementation.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q21:{
            description : ' SRAMs are optimized for storage density.',
            result: 'F',
            answer: 'unknown',
            activeColor: 'black',
          },
          q22:{
            description : 'TLBs are placed on a special cache memory.',
            result: 'T',
            answer: 'unknown',
            activeColor: 'black',
          },
        },
      },
      methods: {
        mid1TrueOrFalse: function (result, key, choose) {
          console.log(result + ' <--> ' + choose)
          if (result === choose) {
            this.mid1[key].answer = 'correct'
            this.mid1[key].activeColor = 'green'
          } else {
            this.mid1[key].answer = 'incorrect'
            this.mid1[key].activeColor = 'red'
          }
        },
        quizTrueOrFalse: function (result, key, choose) {
          console.log(result + ' <--> ' + choose)
          if (result === choose) {
            this.quiz[key].answer = 'correct'
            this.quiz[key].activeColor = 'green'
          } else {
            this.quiz[key].answer = 'incorrect'
            this.quiz[key].activeColor = 'red'
          }
        },
        mid2TrueOrFalse: function (result, key, choose) {
          console.log(result + ' <--> ' + choose)
          if (result === choose) {
            this.mid2[key].answer = 'correct'
            this.mid2[key].activeColor = 'green'
          } else {
            this.mid2[key].answer = 'incorrect'
            this.mid2[key].activeColor = 'red'
          }
        },
        mid2Choice: function (rc, key, content) {
          if (rc.result === 'T') {
            this.mid2MultiChoice[key].choices[content].color = 'green'
            console.log(content + ' <--> ' + ' '+ ' <--> ' + this.mid2MultiChoice[key].choices[content].color)
          } else {
            this.mid2MultiChoice[key].choices[content].color = 'red'
            console.log(content + ' <--> ' + ' ' + ' <--> ' + this.mid2MultiChoice[key].choices[content].color)
          }
        },
      }
    })
  </script>
</body>
</html> 